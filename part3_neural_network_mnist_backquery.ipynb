{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "# scipy.special for the sigmoid function expit()\n",
    "import scipy.special\n",
    "# library for plotting arrays\n",
    "import matplotlib.pyplot\n",
    "# ensure the plots are inside this notebook, not an external window\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# neural network class definition\n",
    "class neuralNetwork:\n",
    "    \n",
    "    # initialise the neural network\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        # set number of nodes in each input, hidden, output layer\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "        \n",
    "        # link weight matrices, wih the who\n",
    "        # weights inside the arrays are w_i_j, where link is from node i to\n",
    "#node j in the next layer\n",
    "        # w11 w21\n",
    "        # w12 w22 etc\n",
    "        self.wih = numpy.random.normal (0.0, pow (self.inodes, -0.5),\n",
    "                                       (self.hnodes, self.inodes))\n",
    "        self.who = numpy.random.normal (0.0, pow (self.hnodes, -0.5), \n",
    "                                       (self.onodes, self.hnodes))\n",
    "        # learning rate\n",
    "        self.lr = learningrate\n",
    "        \n",
    "        # activation function is the sigmoid function\n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "        self.inverse_activation_function = lambda x: scipy.special.logit(x)\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    # train the neural network\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        targets = numpy.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs) \n",
    "        # calculate the signals emerging from hidden layer \n",
    "        hidden_outputs = self.activation_function(hidden_inputs) \n",
    "        \n",
    "        # calculate signals into final output layer \n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs) \n",
    "        # calculate the signals emerging from final output layer \n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        # output layer error is the (target - actual) \n",
    "        output_errors = targets - final_outputs \n",
    "        # hidden layer error is the output_errors, split by weights, recombined at hidden nodes \n",
    "        hidden_errors = numpy.dot(self.who.T, output_errors) \n",
    "        \n",
    "        # update the weights for the links between the hidden and output layers \n",
    "        self.who += self.lr * numpy.dot((output_errors * \n",
    "                                         final_outputs * (1.0 - final_outputs)), \n",
    "                                        numpy.transpose(hidden_outputs)) \n",
    "        #update the weights for the links between the input and hidden layers \n",
    "        self.wih += self.lr * numpy.dot((hidden_errors * hidden_outputs * \n",
    "                                         (1.0 - hidden_outputs)), numpy.transpose(inputs))        \n",
    "        pass\n",
    "    \n",
    "    # query the neural network\n",
    "    def query(self, inputs_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin = 2). T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = numpy.dot (self.wih, inputs)\n",
    "        #calculate the signals emerging from hidden layer \n",
    "        hidden_outputs = self.activation_function(hidden_inputs) \n",
    "        \n",
    "        #calculate signals into final output layer \n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs) \n",
    "        #calculate the signals emerging from final output layer \n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        return final_outputs\n",
    "    \n",
    "    # backquery the neural network\n",
    "    # we'll use the same termnimology to each item, \n",
    "    # eg target are the values at the right of the network, albeit used as input\n",
    "    # eg hidden_output is the signal to the right of the middle nodes\n",
    "    def backquery(self, targets_list):\n",
    "        # transpose the targets list to a vertical array\n",
    "        final_outputs = numpy.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        # calculate the signal into the final output layer\n",
    "        final_inputs = self.inverse_activation_function(final_outputs)\n",
    "\n",
    "        # calculate the signal out of the hidden layer\n",
    "        hidden_outputs = numpy.dot(self.who.T, final_inputs)\n",
    "        # scale them back to 0.01 to .99\n",
    "        hidden_outputs -= numpy.min(hidden_outputs)\n",
    "        hidden_outputs /= numpy.max(hidden_outputs)\n",
    "        hidden_outputs *= 0.98\n",
    "        hidden_outputs += 0.01\n",
    "        \n",
    "        # calculate the signal into the hidden layer\n",
    "        hidden_inputs = self.inverse_activation_function(hidden_outputs)\n",
    "        \n",
    "        # calculate the signal out of the input layer\n",
    "        inputs = numpy.dot(self.wih.T, hidden_inputs)\n",
    "        # scale them back to 0.01 to .99\n",
    "        inputs -= numpy.min(inputs)\n",
    "        inputs /= numpy.max(inputs)\n",
    "        inputs *= 0.98\n",
    "        inputs += 0.01\n",
    "        \n",
    "        return inputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#number of input, hidden and output nodes \n",
    "input_nodes = 784\n",
    "#try 100 and 200 nodes, we take 200 nodes.\n",
    "hidden_nodes = 200\n",
    "output_nodes = 10 \n",
    "\n",
    "#learning rate\n",
    "learning_rate = 0.1\n",
    "\n",
    "#create instance of neural network \n",
    "n = neuralNetwork(input_nodes,hidden_nodes,output_nodes, learning_rate) \n",
    "\n",
    "#load the mnist training data CSV file into a list \n",
    "training_data_file = open(\"/Users/hcl/Desktop/mnist_dataset/mnist_train.csv\", 'r')\n",
    "training_data_list = training_data_file.readlines() \n",
    "training_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-8fb66f12276a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m#all_values[0] is the target label for this record\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.99\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-a5e55eaaa3d2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, inputs_list, targets_list)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# calculate signals into hidden layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mhidden_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;31m# calculate the signals emerging from hidden layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mhidden_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#train the neural network \n",
    "\n",
    "#epochs is the number of times the training data set is used for training \n",
    "epochs = 5\n",
    "for e in range(epochs): \n",
    "    #go through all records in the training data set\n",
    "    for record in training_data_list: \n",
    "        #split the record by the',' commas \n",
    "        all_values = record.split(',') \n",
    "        #scale and shift the inputs \n",
    "        inputs = (numpy.asfarray(all_values[1:])/ 255.0 * 0.99) + 0.01 \n",
    "        #create the target output values (all 0.01, except the desired label which is 0.99) \n",
    "        targets = numpy.zeros(output_nodes) + 0.01 \n",
    "        #all_values[0] is the target label for this record \n",
    "        targets[int(all_values[0])] = 0.99 \n",
    "        n.train(inputs, targets) \n",
    "        pass \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the mnist test data CSV file into a list# load  \n",
    "test_data_file = open(\"/Users/hcl/Desktop/mnist_dataset/mnist_test.csv\", 'r')\n",
    "test_data_list = test_data_file.readlines()\n",
    "test_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the neural network\n",
    "\n",
    "# scorecard for how well the network performs, initially empty\n",
    "scorecard = []\n",
    "\n",
    "# go through all the records in the test data set\n",
    "for record in test_data_list:\n",
    "    # split the record by the ',' commas\n",
    "    all_values = record.split(',')\n",
    "    # correct answer is first value\n",
    "    correct_label = int(all_values[0])\n",
    "    # scale and shift the inputs\n",
    "    inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "    # query the network\n",
    "    outputs = n.query(inputs)\n",
    "    # the index of the highest value corresponds to the label\n",
    "    label = numpy.argmax(outputs)\n",
    "    # append correct or incorrect to list\n",
    "    if (label == correct_label):\n",
    "        # network's answer matches correct answer, add 1 to scorecard\n",
    "        scorecard.append(1)\n",
    "    else:\n",
    "        # network's answer doesn't match correct answer, add 0 to scorecard\n",
    "        scorecard.append(0)\n",
    "        pass\n",
    "    \n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance =  0.0958\n"
     ]
    }
   ],
   "source": [
    "# calculate the performance score, the fraction of correct answers\n",
    "scorecard_array = numpy.asarray(scorecard)\n",
    "print (\"performance = \", scorecard_array.sum() / scorecard_array.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11b1126a0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1174917b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run the network backwards, given a label, see what image it produces\n",
    "\n",
    "# label to test\n",
    "label = 0\n",
    "# create the output signals for this label\n",
    "targets = numpy.zeros(output_nodes) + 0.01\n",
    "# all_values[0] is the target label for this record\n",
    "targets[label] = 0.99\n",
    "print(targets)\n",
    "\n",
    "# get image data\n",
    "image_data = n.backquery(targets)\n",
    "\n",
    "# plot image data\n",
    "matplotlib.pyplot.imshow(image_data.reshape(28,28), cmap='Greys', interpolation='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
