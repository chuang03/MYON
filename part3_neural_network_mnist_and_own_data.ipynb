{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "# scipy.special for the sigmoid function expit()\n",
    "import scipy.special\n",
    "# library for plotting arrays\n",
    "import matplotlib.pyplot\n",
    "# ensure the plots are inside this notebook, not an external window\n",
    "%matplotlib inline\n",
    "# helper to load data from PNG image files\n",
    "import imageio\n",
    "# glob helps select multiple files using patterns\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# neural network class definition\n",
    "class neuralNetwork:\n",
    "    \n",
    "    # initialise the neural network\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        # set number of nodes in each input, hidden, output layer\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "        \n",
    "        # link weight matrices, wih the who\n",
    "        # weights inside the arrays are w_i_j, where link is from node i to\n",
    "#node j in the next layer\n",
    "        # w11 w21\n",
    "        # w12 w22 etc\n",
    "        self.wih = numpy.random.normal (0.0, pow (self.inodes, -0.5),\n",
    "                                       (self.hnodes, self.inodes))\n",
    "        self.who = numpy.random.normal (0.0, pow (self.hnodes, -0.5), \n",
    "                                       (self.onodes, self.hnodes))\n",
    "        # learning rate\n",
    "        self.lr = learningrate\n",
    "        \n",
    "        # activation function is the sigmoid function\n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    # train the neural network\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        targets = numpy.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs) \n",
    "        # calculate the signals emerging from hidden layer \n",
    "        hidden_outputs = self.activation_function(hidden_inputs) \n",
    "        \n",
    "        # calculate signals into final output layer \n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs) \n",
    "        # calculate the signals emerging from final output layer \n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        # output layer error is the (target - actual) \n",
    "        output_errors = targets - final_outputs \n",
    "        # hidden layer error is the output_errors, split by weights, recombined at hidden nodes \n",
    "        hidden_errors = numpy.dot(self.who.T, output_errors) \n",
    "        \n",
    "        # update the weights for the links between the hidden and output layers \n",
    "        self.who += self.lr * numpy.dot((output_errors * \n",
    "                                         final_outputs * (1.0 - final_outputs)), \n",
    "                                        numpy.transpose(hidden_outputs)) \n",
    "        #update the weights for the links between the input and hidden layers \n",
    "        self.wih += self.lr * numpy.dot((hidden_errors * hidden_outputs * \n",
    "                                         (1.0 - hidden_outputs)), numpy.transpose(inputs))        \n",
    "        pass\n",
    "    \n",
    "    # query the neural network\n",
    "    def query(self, inputs_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin = 2). T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = numpy.dot (self.wih, inputs)\n",
    "        #calculate the signals emerging from hidden layer \n",
    "        hidden_outputs = self.activation_function(hidden_inputs) \n",
    "        \n",
    "        #calculate signals into final output layer \n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs) \n",
    "        #calculate the signals emerging from final output layer \n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        return final_outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#number of input, hidden and output nodes \n",
    "input_nodes = 784\n",
    "#try 100 and 200 nodes, we take 200 nodes.\n",
    "hidden_nodes = 200\n",
    "output_nodes = 10 \n",
    "\n",
    "#try learning rate is 0.3, 0.6, 0.1, 0.2, we take learning rate 0.1.\n",
    "learning_rate = 0.1\n",
    "\n",
    "#create instance of neural network \n",
    "n = neuralNetwork(input_nodes,hidden_nodes,output_nodes, learning_rate) \n",
    "\n",
    "#load the mnist training data CSV file into a list \n",
    "training_data_file = open(\"/Users/hcl/Desktop/mnist_dataset/mnist_train.csv\", 'r')\n",
    "training_data_list = training_data_file.readlines() \n",
    "training_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the neural network \n",
    "\n",
    "#epochs is the number of times the training data set is used for training \n",
    "epochs = 10\n",
    "for e in range(epochs): \n",
    "    #go through all records in the training data set\n",
    "    for record in training_data_list: \n",
    "        #split the record by the',' commas \n",
    "        all_values = record.split(',') \n",
    "        #scale and shift the inputs \n",
    "        inputs = (numpy.asfarray(all_values[1:])/ 255.0 * 0.99) + 0.01 \n",
    "        #create the target output values (all 0.01, except the desired label which is 0.99) \n",
    "        targets = numpy.zeros(output_nodes) + 0.01 \n",
    "        #all_values[0] is the target label for this record \n",
    "        targets[int(all_values[0])] = 0.99 \n",
    "        n.train(inputs, targets) \n",
    "        pass \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# our own image test data set\n",
    "our_own_dataset = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ...  /Users/hcl/Desktop/my_own_images/3.png\n",
      "0.044223\n",
      "0.22509\n",
      "loading ...  /Users/hcl/Desktop/my_own_images/5.png\n",
      "0.107816\n",
      "0.337678\n",
      "loading ...  /Users/hcl/Desktop/my_own_images/6.png\n",
      "0.0453838\n",
      "0.229691\n",
      "loading ...  /Users/hcl/Desktop/my_own_images/7.png\n",
      "0.0950507\n",
      "0.359051\n",
      "loading ...  /Users/hcl/Desktop/my_own_images/8.png\n",
      "0.118912\n",
      "0.326431\n"
     ]
    }
   ],
   "source": [
    "for image_file_name in glob.glob(\"/Users/hcl/Desktop/my_own_images/?.png\"):\n",
    "    print (\"loading ... \", image_file_name)\n",
    "    # use the filename to set the correct label\n",
    "    label = int(image_file_name[-5:-4])\n",
    "    # load image data from png files into an array\n",
    "    img_array = imageio.imread(image_file_name, as_gray=True)\n",
    "    # reshape from 28x28 to list of 784 values, invert values\n",
    "    img_data  = 255.0 - img_array.reshape(784)\n",
    "    # then scale data to range from 0.01 to 1.0\n",
    "    img_data = (img_data / 255.0 * 0.99) + 0.01\n",
    "    print(numpy.min(img_data))\n",
    "    print(numpy.max(img_data))\n",
    "    # append label and image data  to test data set\n",
    "    record = numpy.append(label,img_data)\n",
    "    #print(record)\n",
    "    our_own_dataset.append(record)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.05563401]\n",
      " [ 0.00842533]\n",
      " [ 0.03183933]\n",
      " [ 0.16670948]\n",
      " [ 0.00691207]\n",
      " [ 0.10681697]\n",
      " [ 0.04894607]\n",
      " [ 0.01104872]\n",
      " [ 0.2645101 ]\n",
      " [ 0.01984903]]\n",
      "network says  8\n",
      "match!\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niuEncorhJ3KK4SdyiuEncorhJ3Lq/wHbAT290cwxsAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1145cf4e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test the neural network with our own images\n",
    "\n",
    "# record to test\n",
    "item = 4\n",
    "\n",
    "# plot image\n",
    "matplotlib.pyplot.imshow(our_own_dataset[item][1:].reshape(28,28), cmap='Greys', interpolation='None')\n",
    "\n",
    "# correct answer is first value\n",
    "correct_label = our_own_dataset[item][0]\n",
    "# data is remaining values\n",
    "inputs = our_own_dataset[item][1:]\n",
    "\n",
    "# query the network\n",
    "outputs = n.query(inputs)\n",
    "print (outputs)\n",
    "\n",
    "# the index of the highest value corresponds to the label\n",
    "label = numpy.argmax(outputs)\n",
    "print(\"network says \", label)\n",
    "# append correct or incorrect to list\n",
    "if (label == correct_label):\n",
    "    print (\"match!\")\n",
    "else:\n",
    "    print (\"no match!\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
